{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples of Collaborative Filtering based Recommendation Systems**...\n",
    "\n",
    "reference website: https://blog.csdn.net/Jack_yun_feng/article/details/100176399\n",
    "\n",
    "这个model base的想法是这样的，用类似linear regression来预测每个user对每个product的评分，预测出评分高的product就推荐给user。\n",
    "\n",
    "网站都在上面，不懂的自己理解\n",
    "\n",
    "(个人想法是这个逻辑比较很简单，也符合我们project的要求，但是问题是product评分高，并不能说明user会买他，只能说明product好)"
   ]
  },
  {
   "source": [
    "一开始先import\n",
    "然后用pd加载数据，\n",
    "看看数据长上什么样子"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           UserId   ProductId  Rating   Timestamp\n",
       "0  A39HTATAQ9V7YF  0205616461     5.0  1369699200\n",
       "1  A3JM6GV9MNOF9X  0558925278     3.0  1355443200\n",
       "2  A1Z513UWSAAO0F  0558925278     5.0  1404691200\n",
       "3  A1WMRR494NWEWV  0733001998     4.0  1382572800\n",
       "4  A3IAAVS479H7M7  0737104473     1.0  1274227200"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserId</th>\n      <th>ProductId</th>\n      <th>Rating</th>\n      <th>Timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A39HTATAQ9V7YF</td>\n      <td>0205616461</td>\n      <td>5.0</td>\n      <td>1369699200</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A3JM6GV9MNOF9X</td>\n      <td>0558925278</td>\n      <td>3.0</td>\n      <td>1355443200</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A1Z513UWSAAO0F</td>\n      <td>0558925278</td>\n      <td>5.0</td>\n      <td>1404691200</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A1WMRR494NWEWV</td>\n      <td>0733001998</td>\n      <td>4.0</td>\n      <td>1382572800</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A3IAAVS479H7M7</td>\n      <td>0737104473</td>\n      <td>1.0</td>\n      <td>1274227200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#make necesarry imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "dataset = pd.read_csv(\"ratings_Beauty.csv\")\n",
    "dataset = dataset[:1000]\n",
    "dataset.head()"
   ]
  },
  {
   "source": [
    "然后根据uersID，和porductId分组， 然后计算平均分，再然后下面的初始化，我也不太明白，反正好像全变成0了"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用户评分数据  groupby 分组  groupby('userId') 根据用户id分组 agg（aggregation聚合）\n",
    "users_ratings = dataset.groupby('UserId').agg([list])\n",
    "# print(users_ratings)\n",
    "# 物品评分数据\n",
    "items_ratings = dataset.groupby('ProductId').agg([list])\n",
    "# print(items_ratings)\n",
    "# 计算全局平均分\n",
    "global_mean = dataset['Rating'].mean()\n",
    "# 初始化bu bi\n",
    "bu = dict(zip(users_ratings.index, np.zeros(len(users_ratings))))\n",
    "bi = dict(zip(items_ratings.index, np.zeros(len(items_ratings))))\n"
   ]
  },
  {
   "source": [
    "预测function嘛，很简单，平均值加上每个的偏差值就是预测值了"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(uid, iid):\n",
    "    predict_rating = global_mean + bu[uid] + bi[iid]\n",
    "    return predict_rating"
   ]
  },
  {
   "source": [
    "然后把它们都封装在一个class里面，听上去就很厉害，就把要用的function写在一个class，比较好用\n",
    "\n",
    "-init肯定就存一开始的变量。number_epochs是训练的次数，alpha: learning rate，regression rate，colums就是数据集的columns的名字\n",
    "\n",
    "-fit function就也是存变量，然后把数据处理一下，分组什么的，users_rating就是每个userId对每个product的rating，好像是这样的，-items_ratings就是给product打过分的userId和rating，最后会叫sgd()来训练整个model。\n",
    "\n",
    "-然后sgd()就是用梯度下降法(gradient descent)来提高预测的精度，代码自己看，不懂问我也没用。。。\n",
    "\n",
    "predict跟上面的一样，没上面好讲的\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineCFBySGD(object):\n",
    "\n",
    "    def __init__(self, number_epochs, alpha, reg, columns=[\"UserId\", \"ProductId\", \"Rating\"]):\n",
    "        # 梯度下降最高迭代次数\n",
    "        self.number_epochs = number_epochs\n",
    "        # 学习率\n",
    "        self.alpha = alpha\n",
    "        # 正则参数\n",
    "        self.reg = reg\n",
    "        # 数据集中user-item-rating字段的名称\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        '''\n",
    "        :param dataset: uid, iid, rating\n",
    "        :return:\n",
    "        '''\n",
    "        self.dataset = dataset\n",
    "        # 用户评分数据\n",
    "        self.users_ratings = dataset.groupby(self.columns[0]).agg([list])[[self.columns[1], self.columns[2]]]\n",
    "        # 物品评分数据\n",
    "        self.items_ratings = dataset.groupby(self.columns[1]).agg([list])[[self.columns[0], self.columns[2]]]\n",
    "        # 计算全局平均分\n",
    "        self.global_mean = self.dataset[self.columns[2]].mean()\n",
    "        # 调用sgd方法训练模型参数\n",
    "        self.bu, self.bi = self.sgd()\n",
    "\n",
    "    def sgd(self):\n",
    "        '''\n",
    "        利用随机梯度下降，优化bu，bi的值\n",
    "        :return: bu, bi\n",
    "        '''\n",
    "        # 初始化bu、bi的值，全部设为0\n",
    "        bu = dict(zip(self.users_ratings.index, np.zeros(len(self.users_ratings))))\n",
    "        bi = dict(zip(self.items_ratings.index, np.zeros(len(self.items_ratings))))\n",
    "\n",
    "        for i in range(self.number_epochs):\n",
    "        #   print(\"iter%d\" % i)\n",
    "            for uid, iid, real_rating, _ in self.dataset.itertuples(index=False):\n",
    "                error = real_rating - (self.global_mean + bu[uid] + bi[iid])\n",
    "\n",
    "                bu[uid] += self.alpha * (error - self.reg * bu[uid])\n",
    "                bi[iid] += self.alpha * (error - self.reg * bi[iid])\n",
    "\n",
    "        return bu, bi\n",
    "\n",
    "    def predict(self, uid, iid):\n",
    "        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]\n",
    "        return predict_rating\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "加载数据，\n",
    "\n",
    "先用一千个数据做做实验，数据太多，计算会很慢，\n",
    "\n",
    "然后用创好object，然后跑跑fit function。就training好了 \n",
    "\n",
    "然后会弹出可输入值的窗口，复制userId和productId就可以看它预测的值了,自己可以试试，看看预测的怎么样"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "           UserId   ProductId  Rating   Timestamp\n",
      "0  A39HTATAQ9V7YF  0205616461     5.0  1369699200\n",
      "1  A3JM6GV9MNOF9X  0558925278     3.0  1355443200\n",
      "2  A1Z513UWSAAO0F  0558925278     5.0  1404691200\n",
      "3  A1WMRR494NWEWV  0733001998     4.0  1382572800\n",
      "4  A3IAAVS479H7M7  0737104473     1.0  1274227200\n",
      "\n",
      "Empty input, break\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = pd.read_csv(\"ratings_Beauty.csv\")\n",
    "dataset = dataset[:1000]\n",
    "print(dataset.head(5))\n",
    "bcf = BaselineCFBySGD(20, 0.1, 0.1, [\"UserId\", \"ProductId\", \"Rating\"])\n",
    "bcf.fit(dataset)\n",
    "print()\n",
    "\n",
    "for _ in range(2):\n",
    "    try:\n",
    "        # Remove input spaces: .strip()\n",
    "        uid = input(\"uid: \").strip()\n",
    "        iid = input(\"iid: \").strip()\n",
    "        print(bcf.predict(uid, iid))\n",
    "    except:\n",
    "        print (\"Empty input, break\")\n",
    "        break\n"
   ]
  },
  {
   "source": [
    "下面部分是为了能够测试整个逻辑的准确性\n",
    "\n",
    "data_split()就是分割数据，training和testing的数据集百分之八十是trianing，剩下的是testing的，\n",
    "\n",
    "反正源代码这这样写，看看，随便改"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(dataset, x=0.8, random=False):\n",
    "    '''\n",
    "    切分数据集， 这里为了保证用户数量保持不变，将每个用户的评分数据按比例进行拆分\n",
    "    :param data_path: 数据集路径\n",
    "    :param x: 训练集的比例，如x=0.8，则0.2是测试集\n",
    "    :param random: 是否随机切分，默认False\n",
    "    :return: 用户-物品评分矩阵\n",
    "    '''\n",
    "    print(\"开始切分数据集...\")\n",
    "    # 设置要加载的数据字段的类型\n",
    "    # dtype = {\"userId\": np.int32, \"movieId\": np.int32, \"rating\": np.float32}\n",
    "    # 加载数据，我们只用前三列数据，分别是用户ID，电影ID，已经用户对电影的对应评分\n",
    "    # ratings = pd.read_csv(data_path, dtype=dtype, usecols=range(3))\n",
    "    ratings = dataset\n",
    "\n",
    "    testset_index = []\n",
    "    # 为了保证每个用户在测试集和训练集都有数据，因此按userId聚合\n",
    "    for uid in ratings.groupby(\"UserId\").any().index:\n",
    "        user_rating_data = ratings.where(ratings[\"UserId\"]==uid).dropna()\n",
    "        if random:\n",
    "            # 因为不可变类型不能被 shuffle方法作用，所以需要强行转换为列表\n",
    "            index = list(user_rating_data.index)\n",
    "            np.random.shuffle(index)    # 打乱列表\n",
    "            _index = round(len(user_rating_data) * x)\n",
    "            testset_index += list(index[_index:])\n",
    "        else:\n",
    "            # 将每个用户的x比例的数据作为训练集，剩余的作为测试集\n",
    "            index = round(len(user_rating_data) * x)\n",
    "            testset_index += list(user_rating_data.index.values[index:])\n",
    "\n",
    "    testset = ratings.loc[testset_index]\n",
    "    trainset = ratings.drop(testset_index)\n",
    "    print(\"完成数据集切分...\")\n",
    "    return trainset, testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "然后就是用trainset，来训练model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "开始切分数据集...\n",
      "完成数据集切分...\n",
      "iter0\n",
      "iter1\n",
      "iter2\n",
      "iter3\n",
      "iter4\n",
      "iter5\n",
      "iter6\n",
      "iter7\n",
      "iter8\n",
      "iter9\n",
      "iter10\n",
      "iter11\n",
      "iter12\n",
      "iter13\n",
      "iter14\n",
      "iter15\n",
      "iter16\n",
      "iter17\n",
      "iter18\n",
      "iter19\n"
     ]
    }
   ],
   "source": [
    "#Training data\n",
    "trainset, testset = data_split(dataset, random=True)\n",
    "bcf = BaselineCFBySGD(20, 0.1, 0.1, [\"UserId\", \"ProductId\", \"Rating\"])\n",
    "bcf.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "然后把预测结果放在这list里面，随意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_rating =[]\n",
    "for uid, iid, real_rating, _ in trainset.itertuples(index=False):\n",
    "    pred_rating_result = (uid, iid,real_rating,bcf.predict(uid, iid))\n",
    "    pred_rating.append(pred_rating_result)\n"
   ]
  },
  {
   "source": [
    "再下面，就是计算逻辑准确度来，源代码有两种，一个叫rmse（均方根误差），另一个mae（平均绝对误差），反正都是看误差的。\n",
    "\n",
    "<img src=\"img/rmse.png\" width=\"30%\">\n",
    "<img src=\"img/mae.png\" width=\"30%\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuray(predict_results, method=\"all\"):\n",
    "    '''\n",
    "    准确性指标计算方法\n",
    "    :param predict_results: 预测结果，类型为容器，每个元素是一个包含uid,iid,real_rating,pred_rating的序列\n",
    "    :param method: 指标方法，类型为字符串，rmse或mae，否则返回两者rmse和mae\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    def rmse(predict_results):\n",
    "        '''\n",
    "        rmse评估指标 (均方根误差)\n",
    "        :param predict_results:\n",
    "        :return: rmse\n",
    "        '''\n",
    "        length = 0\n",
    "        _rmse_sum = 0\n",
    "        for uid, iid, real_rating, pred_rating in predict_results:\n",
    "            length += 1\n",
    "            _rmse_sum += (pred_rating - real_rating) ** 2\n",
    "        return round(np.sqrt(_rmse_sum / length), 4)\n",
    "\n",
    "    def mae(predict_results):\n",
    "        '''\n",
    "        mae评估指标 (平均绝对误差)\n",
    "        :param predict_results:\n",
    "        :return: mae\n",
    "        '''\n",
    "        length = 0\n",
    "        _mae_sum = 0\n",
    "        for uid, iid, real_rating, pred_rating in predict_results:\n",
    "            length += 1\n",
    "            _mae_sum += abs(pred_rating - real_rating)\n",
    "        return round(_mae_sum / length, 4)\n",
    "\n",
    "    def rmse_mae(predict_results):\n",
    "        '''\n",
    "        rmse和mae评估指标\n",
    "        :param predict_results:\n",
    "        :return: rmse, mae\n",
    "        '''\n",
    "        length = 0\n",
    "        _rmse_sum = 0\n",
    "        _mae_sum = 0\n",
    "        for uid, iid, real_rating, pred_rating in predict_results:\n",
    "            length += 1\n",
    "            _rmse_sum += (pred_rating - real_rating) ** 2\n",
    "            _mae_sum += abs(pred_rating - real_rating)\n",
    "        return round(np.sqrt(_rmse_sum / length), 4), round(_mae_sum / length, 4)\n",
    "\n",
    "    if method.lower() == \"rmse\":\n",
    "        rmse(predict_results)\n",
    "    elif method.lower() == \"mae\":\n",
    "        mae(predict_results)\n",
    "    else:\n",
    "        return rmse_mae(predict_results)"
   ]
  },
  {
   "source": [
    "剩下需要做的就是调整 BaselineCFBySGD(20, 0.1, 0.1, [\"UserId\", \"ProductId\", \"Rating\"])里面的参数，来得出准确率的趋势\n",
    "\n",
    "比如20到100次的训练次数，看误差最小是多少次数，可以用plt来画图，看趋势\n",
    "\n",
    "或者在误差最小的时候的次数，再调小学习率，更一步降低误差（应该可以。。）\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.203 0.1513\n"
     ]
    }
   ],
   "source": [
    "a , b = accuray(pred_rating)\n",
    "print(a,b)"
   ]
  },
  {
   "source": [
    "然后再看看其他什么想弄的， 暂时还没想好。。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}